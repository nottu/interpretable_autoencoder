{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.interpolation import rotate as sc_rotate\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.optimize import curve_fit, least_squares, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radioreader import *\n",
    "from methods import *\n",
    "from kittler import kittler_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'unlrg'\n",
    "ext = 'fits'\n",
    "names = glob.glob('{0}/*.{1}*'.format(directory, ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d71e7c9d4ee47888817a68caca58202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=399), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for n in tqdm(range(len(names))):\n",
    "    im = readImg(names[n], normalize=True, sz=128)\n",
    "    k = kittler_float(im, copy=False)\n",
    "    images.append( np.expand_dims(k, axis=0) )\n",
    "    del im\n",
    "    del k\n",
    "# images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([399, 1, 128, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_tensor = torch.tensor(images)\n",
    "im_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([399, 1, 128, 128])\n",
      "imh, imw =  128 128\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#arguments\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "ts = list(im_tensor.shape)\n",
    "imh, imw = ts[2], ts[3]\n",
    "print(im_tensor.shape)\n",
    "print('imh, imw = ',imh, imw)\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9 # 'SGD momentum'\n",
    "latent_space=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, height, width, device):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.device = device\n",
    "\n",
    "        self.feat_sz = (imh - 6) * (imw - 6)\n",
    "        \n",
    "        # Init model layers\n",
    "        self.down1 = nn.Conv2d( 1,  8, 3) #shape -2\n",
    "        self.down2 = nn.Conv2d( 8, 16, 3) #shape -2\n",
    "        self.down3 = nn.Conv2d(16, 16, 3) #shape -2\n",
    "        \n",
    "        self.latentd = nn.Linear(16 * self.feat_sz, 16)\n",
    "        #decoder\n",
    "        self.latentu = nn.Linear(16, self.feat_sz * 16)\n",
    "        \n",
    "        self.up3   = nn.ConvTranspose2d(16, 16, 3)\n",
    "        self.up2   = nn.ConvTranspose2d(16, 8, 3)\n",
    "        self.up1   = nn.ConvTranspose2d(8, 1, 3)\n",
    "        \n",
    "    def encode(self, x, params):\n",
    "        x = F.relu(self.down1(x))\n",
    "        x = F.relu(self.down2(x))\n",
    "        x = F.relu(self.down3(x))\n",
    "        x =  x.view(-1, 16 * (imh - 6) * (imw - 6)) #flatten\n",
    "        x = self.latentd(x)\n",
    "        x = self.feature_transformer(x, params)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        x = self.latentu(x)\n",
    "        x = x.view(-1, 16, (imh - 6), (imw - 6))\n",
    "        x = F.relu(self.up3(x))\n",
    "        x = F.relu(self.up2(x))\n",
    "        x = torch.sigmoid(self.up1(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, params):\n",
    "        return self.decode(self.encode(x, params))\n",
    "    \n",
    "    def feature_transformer(self, input, params):\n",
    "        \"\"\"For now we assume the params are just a single rotation angle\n",
    "\n",
    "        Args:\n",
    "            input: [N,c] tensor, where c = 2*int\n",
    "            params: [N,1] tensor, with values in [0,2*pi)\n",
    "        Returns:\n",
    "            [N,c] tensor\n",
    "        \"\"\"\n",
    "        # First reshape activations into [N,c/2,2,1] matrices\n",
    "        x = input.view(input.size(0),input.size(1)//2,2,1)\n",
    "        # Construct the transformation matrix\n",
    "        sin = torch.sin(params)\n",
    "        cos = torch.cos(params)\n",
    "        transform = torch.cat([sin, -cos, cos, sin], 1)\n",
    "        transform = transform.view(transform.size(0),1,2,2).to(self.device)\n",
    "        # Multiply: broadcasting taken care of automatically\n",
    "        # [N,1,2,2] @ [N,channels/2,2,1]\n",
    "        output = torch.matmul(transform, x)\n",
    "        # Reshape and return\n",
    "        return output.view(input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_tensor(input):\n",
    "    \"\"\"Nasty hack to rotate images in a minibatch, this should be parallelized\n",
    "    and set in PyTorch\n",
    "\n",
    "    Args:\n",
    "        input: [N,c,h,w] **numpy** tensor\n",
    "    Returns:\n",
    "        rotated output and angles in radians\n",
    "    \"\"\"\n",
    "    angles = 2*np.pi*np.random.rand(input.shape[0])\n",
    "    angles = angles.astype(np.float32)\n",
    "    outputs = []\n",
    "    for i in range(input.shape[0]):\n",
    "        output = sc_rotate(input[i,...], 180*angles[i]/np.pi, axes=(1,2), reshape=False)\n",
    "        outputs.append(output)\n",
    "    return np.stack(outputs, 0), angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # Reshape data\n",
    "        targets, angles = rotate_tensor(data.numpy())\n",
    "        targets = torch.from_numpy(targets).to(device, dtype=torch.float)\n",
    "        angles = torch.from_numpy(angles).to(device)\n",
    "        angles = angles.view(angles.size(0), 1)\n",
    "\n",
    "        # Forward pass\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, angles)\n",
    "\n",
    "        # Binary cross entropy loss\n",
    "        loss_fnc = nn.BCELoss(reduction='sum')\n",
    "        loss = loss_fnc(output, targets)\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            sys.stdout.write('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\r'\n",
    "                .format(epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(imh, imw, device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 28.7 ms, total: 42.8 ms\n",
      "Wall time: 57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(im_tensor, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     start = time.time()\n",
    "#     train(model, device, train_loader, optimizer, epoch)\n",
    "#     end = time.time()\n",
    "#     sys.stdout.write('\\n Time: {0:.2f}s\\n'.format(end - start))\n",
    "\n",
    "model.load_state_dict(torch.load('unlrg_linear_model', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-70b2a12af9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ml00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "l = next(iter(train_loader))\n",
    "l00 = l[:1,:,:]\n",
    "plt.imshow(l00.numpy()[0, 0,:,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rot = 32\n",
    "with torch.no_grad():\n",
    "    angles = torch.linspace(0, 2*np.pi, steps=n_rot)\n",
    "    angles = angles.view(n_rot, 1)\n",
    "\n",
    "    data = l00[0]\n",
    "    data = data.view(data.size(0), -1)\n",
    "    data = data.repeat(n_rot, 1)\n",
    "    data = data.view(-1, 1, imh, imw).to(device, dtype=torch.float)\n",
    "\n",
    "    output = model.encode(data, angles)\n",
    "    output = output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_np = output.numpy()\n",
    "f, ax = plt.subplots(4, 4, figsize=(15, 6))\n",
    "for i in range(4): \n",
    "    for j in range(4):\n",
    "        ax[i][j].plot(o_np[:,i*4 + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dec = model.decode(output.to(device))\n",
    "    dec = dec.cpu().view(-1,1,imh,imw)\n",
    "d_np = dec.numpy()\n",
    "\n",
    "f, ax = plt.subplots(4, 4, figsize=(15, 12))\n",
    "for i in range(4): \n",
    "    for j in range(4):\n",
    "        ax[i][j].imshow(d_np[2*(i*4 + j),0], cmap='gray')\n",
    "        ax[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'unlrg_linear_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
